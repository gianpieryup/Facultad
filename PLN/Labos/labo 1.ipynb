{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e902c023",
   "metadata": {},
   "source": [
    "082057 – Procesamiento del Lenguaje Natural\n",
    "<center><h1>Lab 1</h1> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c8667f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe998a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36732b38",
   "metadata": {},
   "source": [
    "**Para listar las palabras de un texto en particular, puede usar los métodos de tokens. Por ejemplo, los\n",
    "primeros 5 tokens en el corpus de “Moby Dick” (text1) pueden ser obtenidos escribiendo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "981613ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Moby', 'Dick', 'by', 'Herman']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.tokens[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63afc510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre', 'Vinken', ',', '61', 'years']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text7.tokens[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfc5a54",
   "metadata": {},
   "source": [
    "**Notese que puede ver la lista de corpora otra vez, tipeando:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fee0d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "texts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e3fde5",
   "metadata": {},
   "source": [
    "También puede contar el número de ocurrencias de una palabra en particular, usando el método “count”\n",
    "y un parámetro con la palabra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c7c6de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count(\"Moby\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594e31ea",
   "metadata": {},
   "source": [
    "### 4 Strings y expresiones regulares\n",
    "Antes de trabajar con un corpora grande, vamos a tomar una oración simple y mirar a los problemas que\n",
    "deberían tenerse en cuenta cuando procesamos strings.\n",
    "Trate de ejecutar lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6be9170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'cat', 'sat', 'on', 'the', 'mat', '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysent = \"The cat sat on the mat.\"\n",
    "from nltk import word_tokenize\n",
    "mysent_tokens = word_tokenize(mysent)\n",
    "mysent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "059274fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mysent_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f177596b",
   "metadata": {},
   "source": [
    "**word_tokenize** es un método built-in que “tokeniza” una cadena de lenguaje natural. Notese que la\n",
    "tokenización no está basada solamente en separar por espacios.\n",
    "\n",
    "Una forma común de usar expresiones regulares en Python es a través del método re.search. El siguiente\n",
    "fragmento muestra cómo buscar si \"leng\" es una subcadena del texto \"procesamiento del lenguaje\n",
    "natural\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b643e4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(18, 22), match='leng'>\n"
     ]
    }
   ],
   "source": [
    "from nltk import re\n",
    "match_index = re.search(\"leng\", \"procesamiento del lenguaje natural\")\n",
    "if match_index:\n",
    "    print(match_index)\n",
    "else:\n",
    "    print('No es subcadena')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77d5d424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_index.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d33afa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_index.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2b473f",
   "metadata": {},
   "source": [
    "Ahora supongamos que consideramos como palabras, solo aquellos tokens que son alfanuméricos, es decir. solo\n",
    "contienen alfabetos, números o el hiper símbolos. La expresión regular que puede usar para este patrón es \"\\ w\".\n",
    "\n",
    "Por ejemplo este caso usando **mysent** quitamos lo que no es alfanumerico, ej '.' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb122849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'cat', 'sat', 'on', 'the', 'mat']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysent_tokens_nopunct = [word for word in word_tokenize(mysent) if re.search(\"\\w\", word)]\n",
    "mysent_tokens_nopunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1a6b79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mysent_tokens_nopunct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4330b53a",
   "metadata": {},
   "source": [
    "El método set crea un set. Un set por definición, solo tendrá objetos únicos (sin repetición). Por lo tanto,\n",
    "cada palabra aparecerá una vez. Intente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a6706da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The', 'cat', 'mat', 'on', 'sat', 'the'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(mysent_tokens_nopunct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27bcd651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(mysent_tokens_nopunct))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853320d3",
   "metadata": {},
   "source": [
    "Ahora si, estamos listos para aplicar estas técnicas a un corpora más grande, de NLKT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6db16069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moby', 'dick', 'by', 'herman', 'melville']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_dick_tokens = text1.tokens\n",
    "moby_dick_tokens_nopunct = [word.lower() for word in moby_dick_tokens if re.search(\"\\w\", word)]\n",
    "moby_dick_tokens_nopunct[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d4eeac",
   "metadata": {},
   "source": [
    "## 5 Probando sus conocimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe127e9f",
   "metadata": {},
   "source": [
    "1. Cuál es el número de tokens en Moby Dick?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3797743d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218621"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(moby_dick_tokens_nopunct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da3dd6",
   "metadata": {},
   "source": [
    "2. Cuál es el número de types en Moby Dick? Osea 'set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b20e0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17140"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(moby_dick_tokens_nopunct))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63a79e1",
   "metadata": {},
   "source": [
    "El **type-token ratio** es una medida de cuán diverso son los ítems léxicos en un texto dado. Está definido\n",
    "por el número de types dividido por el número de tokens. Cuánto más alto es este ratio, consideramos al\n",
    "texto como más diverso en palabras, también conocido como “diversidad léxica”. En otras palabras,\n",
    "textos con mayor “lexical diversity” usan una gran variedad de palabras, de manera opuesta a los que\n",
    "usan las mismas palabras repetidamente. Para tener una intuición, suponga dos textos que tienen el\n",
    "mismo número de tokens, el que que tiene más types es el más diverso léxicamente.\n",
    "Combinando estos dos métodos para contart types y tokens, puede encontrar el type-token ratio de Moby\n",
    "Dick. Haga lo mismo para el corpus del WSJ (Wall Street Journal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ee6f5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07840051962071347"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Moby_Dick_type_token_ratio = len(set(moby_dick_tokens_nopunct)) / len(moby_dick_tokens_nopunct)\n",
    "Moby_Dick_type_token_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d0de209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.129748424801388"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsj_tokens = text7.tokens\n",
    "wsj_tokens_nopunct = [word.lower() for word in wsj_tokens if re.search(\"\\w\", word)]\n",
    "wsj_type_token_ratio = len(set(wsj_tokens_nopunct)) / len(wsj_tokens_nopunct)\n",
    "wsj_type_token_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0d5bd9",
   "metadata": {},
   "source": [
    "**5. Cuál de los dos tiene más diversidad léxica?**\n",
    "\n",
    "wsj_type_token_ratio > Moby_Dick_type_token_ratio  \n",
    "\n",
    "Entonces (Wall Street Journal) tiene mas diversidad lexica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6743a217",
   "metadata": {},
   "source": [
    "**6. Puede pensar una razón por por la cual ese corpus es más diverso que el otro?**\n",
    "\n",
    "También hablamos en clase sobre estimar probabilidades de un corpus.\n",
    "\n",
    "**RPTA:** Porque al ser un diario, habla de todo tipo de cosas a diferencia de la novela que narra toda una historia continua"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e72b82",
   "metadata": {},
   "source": [
    "**7. Cual es el “Maximum Likelikhood Estimate (MLE)” de la palabra “whale” (ballena) en Moby Dick?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf2e8952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005607878474620462"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_moby_dick_whale = moby_dick_tokens_nopunct.count('whale')  / len(moby_dick_tokens_nopunct)\n",
    "P_moby_dick_whale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7503fcd4",
   "metadata": {},
   "source": [
    "**8. Cuál es el MLE de “whale” en el corpus de WSJ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca5235b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aparentemente no aparece whale en ningún lado, las noticias de ballenas \n",
    "P_wsj_whale = wsj_tokens_nopunct.count('whale')  / len(wsj_tokens_nopunct)\n",
    "P_wsj_whale"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d8ec8f934ab086a4a80c07d89cd0580c6342188aa1d2a54e13fbbc265b40fe9"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
